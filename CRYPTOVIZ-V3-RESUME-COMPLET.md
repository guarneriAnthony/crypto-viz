# ğŸš€ CryptoViz V3.0 - Data Lakehouse
## RÃ©sumÃ© Complet du Projet

### ğŸ¯ QU'EST-CE QUE CRYPTOVIZ ?

**CryptoViz** est une plateforme d'analytics crypto-monnaies temps rÃ©el qui a Ã©voluÃ© Ã  travers 3 versions architecturales majeures pour devenir un **Data Lakehouse moderne**.

**Mission** : Collecter, traiter et visualiser en temps rÃ©el les donnÃ©es de prix et mÃ©triques des cryptomonnaies depuis plusieurs sources APIs, avec une architecture Ã©volutive et performante.

---

### ğŸ—ï¸ ARCHITECTURE V3.0 - DATA LAKEHOUSE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ“Š CRYPTOVIZ V3.0 - DATA LAKEHOUSE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŒ APIs    â”‚    â”‚  ğŸŒ APIs    â”‚    â”‚  ğŸŒ APIs    â”‚    â”‚  ğŸŒ APIs    â”‚
â”‚ CoinGecko   â”‚    â”‚CoinMarketCapâ”‚    â”‚ Binance     â”‚    â”‚ Autres...   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
               â”‚  ğŸ“¥ CRYPTO SCRAPER  â”‚      â”‚
               â”‚   (Data Collector)  â”‚      â”‚
               â”‚                     â”‚      â”‚
               â”‚ â€¢ Multi-providers   â”‚      â”‚
               â”‚ â€¢ Rate limiting     â”‚      â”‚
               â”‚ â€¢ Error handling    â”‚      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                          â”‚                  â”‚
                          â–¼                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
               â”‚   ğŸ“¡ STREAMING       â”‚     â”‚
               â”‚      SERVER          â”‚     â”‚
               â”‚  (Kafka Producer)    â”‚     â”‚
               â”‚                      â”‚     â”‚
               â”‚ â€¢ Dual topics        â”‚     â”‚
               â”‚ â€¢ Batch + Streaming  â”‚     â”‚
               â”‚ â€¢ JSON serialization â”‚     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                          â”‚                  â”‚
                          â–¼                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
               â”‚  ğŸ¾ REDPANDA         â”‚     â”‚
               â”‚  (Message Broker)    â”‚     â”‚
               â”‚                      â”‚     â”‚
               â”‚ â€¢ Kafka-compatible   â”‚     â”‚
               â”‚ â€¢ Port 19092         â”‚     â”‚
               â”‚ â€¢ 3 partitions       â”‚     â”‚
               â”‚ â€¢ Topics:            â”‚     â”‚
               â”‚   - crypto-raw-data  â”‚     â”‚
               â”‚   - crypto-streaming â”‚     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                          â”‚                  â”‚
                          â–¼                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
               â”‚ âš¡ APACHE SPARK      â”‚     â”‚
               â”‚   STREAMING          â”‚     â”‚
               â”‚                      â”‚     â”‚
               â”‚ â€¢ Master (8081)      â”‚     â”‚
               â”‚ â€¢ Worker             â”‚     â”‚
               â”‚ â€¢ Streaming Job      â”‚     â”‚
               â”‚ â€¢ Real-time ETL      â”‚     â”‚
               â”‚ â€¢ Schema validation  â”‚     â”‚
               â”‚ â€¢ Data enrichment    â”‚     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                          â”‚                  â”‚
                          â–¼                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
               â”‚  ğŸ“¦ MINIO S3         â”‚     â”‚
               â”‚  (Object Storage)    â”‚     â”‚
               â”‚                      â”‚     â”‚
               â”‚ â€¢ Port 9002          â”‚     â”‚
               â”‚ â€¢ Bucket: crypto-dataâ”‚     â”‚
               â”‚ â€¢ Parquet format     â”‚     â”‚
               â”‚ â€¢ Snappy compression â”‚     â”‚
               â”‚ â€¢ Partitioning:      â”‚     â”‚
               â”‚   /year/month/day/   â”‚     â”‚
               â”‚   source/crypto/     â”‚     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                          â”‚                  â”‚
                          â–¼                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
               â”‚ ğŸ“Š DASHBOARD V3      â”‚     â”‚
               â”‚   (Streamlit)        â”‚     â”‚
               â”‚                      â”‚     â”‚
               â”‚ â€¢ Port 8501          â”‚     â”‚
               â”‚ â€¢ s3fs reader        â”‚     â”‚
               â”‚ â€¢ Parquet queries    â”‚     â”‚
               â”‚ â€¢ Interactive viz    â”‚     â”‚
               â”‚ â€¢ Real-time charts   â”‚     â”‚
               â”‚ â€¢ DuckDB fallback    â”‚     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¾ DUCKDB       â”‚
â”‚ (Fallback DB)   â”‚
â”‚                 â”‚  
â”‚ â€¢ OLAP engine   â”‚
â”‚ â€¢ Local storage â”‚
â”‚ â€¢ Fast queries  â”‚
â”‚ â€¢ Backup data   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ§¬ COMPOSANTS DÃ‰TAILLÃ‰S

#### 1ï¸âƒ£ **CRYPTO SCRAPER** (Collecteur de donnÃ©es)
- **RÃ´le** : Collecter les donnÃ©es crypto depuis les APIs externes
- **Technologies** : Python, aiohttp, asyncio
- **Providers supportÃ©s** :
  - ğŸŸ¢ **CoinGecko** (gratuit, rate limit 50 req/min)
  - ğŸŸ¡ **CoinMarketCap** (API key, rate limit flexible)
  - ğŸ”µ **Extensible** (architecture modulaire pour nouveaux providers)
- **FonctionnalitÃ©s** :
  - Rate limiting automatique
  - Retry avec backoff exponentiel
  - Validation des donnÃ©es
  - Monitoring des erreurs

#### 2ï¸âƒ£ **STREAMING SERVER** (Kafka Producer)
- **RÃ´le** : Publier les donnÃ©es dans Redpanda/Kafka
- **Technologies** : Python, kafka-python
- **Topics** :
  - `crypto-raw-data` â†’ DonnÃ©es brutes pour batch processing
  - `crypto-streaming` â†’ DonnÃ©es temps rÃ©el pour stream processing
- **Configuration** :
  - SÃ©rialisation JSON
  - Compression automatique
  - Acknowledgment = ALL
  - Batching optimisÃ© (16KB, 10ms linger)

#### 3ï¸âƒ£ **REDPANDA** (Message Broker)
- **RÃ´le** : Message broker compatible Kafka
- **Avantages** :
  - Plus lÃ©ger que Kafka
  - Compatible 100% avec l'API Kafka
  - DÃ©ploiement single-node simplifiÃ©
- **Configuration** :
  - Port 19092 (externe)
  - 3 partitions par topic
  - RÃ©plication factor = 1

#### 4ï¸âƒ£ **APACHE SPARK STREAMING** (ETL temps rÃ©el)
- **RÃ´le** : Traitement des donnÃ©es en streaming vers le Data Lake
- **Architecture** :
  - **Spark Master** (port 8081) - Orchestration
  - **Spark Worker** - ExÃ©cution des tÃ¢ches
  - **Streaming Job** - Application mÃ©tier
- **Traitement** :
  - Lecture depuis Redpanda
  - Validation et nettoyage des donnÃ©es
  - Enrichissement (calcul de mÃ©triques)
  - Partitionnement intelligent
  - Ã‰criture Parquet optimisÃ©e

#### 5ï¸âƒ£ **MINIO S3** (Data Lake Storage)
- **RÃ´le** : Stockage objet compatible S3 pour le Data Lake
- **Format** : Apache Parquet avec compression Snappy
- **Partitionnement** :
  ```
  s3://crypto-data/
  â”œâ”€â”€ year=2025/
  â”‚   â””â”€â”€ month=09/
  â”‚       â””â”€â”€ day=04/
  â”‚           â”œâ”€â”€ source=coingecko/
  â”‚           â”‚   â”œâ”€â”€ crypto=bitcoin/
  â”‚           â”‚   â””â”€â”€ crypto=ethereum/
  â”‚           â””â”€â”€ source=coinmarketcap/
  â”‚               â”œâ”€â”€ crypto=bitcoin/
  â”‚               â””â”€â”€ crypto=ethereum/
  ```
- **Avantages** :
  - Stockage columnaire performant
  - Compression ~70%
  - Query pushdown
  - Schema evolution

#### 6ï¸âƒ£ **DASHBOARD V3** (Interface utilisateur)
- **RÃ´le** : Visualisation interactive des donnÃ©es
- **Technologies** : Streamlit, Plotly, s3fs, pandas
- **FonctionnalitÃ©s** :
  - Lecture directe depuis MinIO avec s3fs
  - Graphiques temps rÃ©el interactifs
  - MÃ©triques de performance
  - SÃ©lection multi-crypto et multi-source
  - Mode Lakehouse + Fallback DuckDB
- **Onglets** :
  - **ğŸ“ˆ Dashboard** : Graphiques principaux
  - **ğŸ” Explorer** : Navigation dans les donnÃ©es
  - **âš¡ Performance** : MÃ©triques Lakehouse
  - **ğŸ“Š Management** : Administration des partitions

#### 7ï¸âƒ£ **DUCKDB** (Fallback Database)
- **RÃ´le** : Base OLAP de secours et cache local
- **Utilisation** :
  - Fallback si MinIO indisponible
  - Cache pour requÃªtes frÃ©quentes
  - DÃ©veloppement et tests

---

### ğŸ”„ FLUX DE DONNÃ‰ES

```
APIs â†’ Scraper â†’ Streaming Server â†’ Redpanda â†’ Spark â†’ MinIO â†’ Dashboard
 â†“                                                              â†‘
DuckDB â†â†â†â†â†â†â†â†â†â†â†â†â† Fallback Consumer â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â”˜
```

**1. Collecte** : Scraper interroge les APIs toutes les 30s
**2. Publication** : Streaming Server publie vers Redpanda
**3. Traitement** : Spark consume et traite en micro-batches
**4. Stockage** : DonnÃ©es Parquet partitionnÃ©es dans MinIO
**5. Visualisation** : Dashboard lit depuis MinIO avec s3fs
**6. Fallback** : DuckDB comme solution de secours

---

### ğŸ¯ POURQUOI CETTE ARCHITECTURE ?

#### **Performance** :
- Format Parquet columnaire â†’ RequÃªtes 10x plus rapides
- Partitionnement intelligent â†’ Scan sÃ©lectif des donnÃ©es
- Spark distribuÃ© â†’ ScalabilitÃ© horizontale
- Cache multi-niveaux â†’ Latence rÃ©duite

#### **FiabilitÃ©** :
- Message broker dÃ©couplÃ© â†’ RÃ©sistance aux pannes
- Stockage objet â†’ DurabilitÃ© 99.999999999%
- Fallback DuckDB â†’ ContinuitÃ© de service
- Retry automatique â†’ Auto-guÃ©rison

#### **Ã‰volutivitÃ©** :
- Architecture microservices â†’ Scaling indÃ©pendant
- Schema evolution â†’ Ajout de champs sans impact
- Providers modulaires â†’ Nouvelles sources facilement
- Format ouvert â†’ InteropÃ©rabilitÃ©

#### **ObservabilitÃ©** :
- MÃ©triques Spark â†’ Monitoring des performances
- Logs structurÃ©s â†’ Debugging facilitÃ©
- Dashboard admin â†’ Vue d'ensemble temps rÃ©el

---

### ğŸ“Š DONNÃ‰ES COLLECTÃ‰ES

**Cryptomonnaies supportÃ©es** : Bitcoin, Ethereum, Binance Coin, Tether, Solana, Ripple, Dogecoin, etc.

**MÃ©triques par crypto** :
- Prix actuel (USD)
- Market cap
- Volume 24h
- Variations (1h, 24h, 7d)
- Timestamp prÃ©cis
- Source de la donnÃ©e

**Enrichissement automatique** :
- Partitions temporelles
- MÃ©tadonnÃ©es d'ingestion
- Offsets Kafka
- Temps de processing

---

### ğŸš€ Ã‰VOLUTIONS FUTURES

**Court terme** :
- Alertes temps rÃ©el
- Plus de cryptos et mÃ©triques
- API REST pour accÃ¨s externe

**Moyen terme** :
- Machine Learning (prÃ©dictions prix)
- Streaming analytics avancÃ©es
- Multi-tenancy

**Long terme** :
- Architecture multi-cloud
- Real-time OLAP avec Apache Druid
- GraphQL API

---

### ğŸ› ï¸ DÃ‰PLOIEMENT

**PrÃ©requis** : Docker, Docker Compose
**Commandes** :
```bash
# DÃ©marrage complet
docker-compose -f docker-compose-v3-spark.yml up -d

# AccÃ¨s aux interfaces
- Dashboard: http://localhost:8501
- Spark UI: http://localhost:8081  
- MinIO UI: http://localhost:9001
- Redpanda Console: http://localhost:9644
```

**Ressources recommandÃ©es** :
- CPU: 4+ cores
- RAM: 8+ GB
- Stockage: 20+ GB SSD

---

### ğŸ¯ RÃ‰SUMÃ‰ EXÃ‰CUTIF

**CryptoViz V3.0** est une plateforme Data Lakehouse moderne qui transforme les donnÃ©es crypto en temps rÃ©el en insights actionnables. L'architecture distribuÃ© avec Spark + MinIO + Redpanda offre performance, fiabilitÃ© et Ã©volutivitÃ© pour traiter des millions de points de donnÃ©es crypto quotidiennement.

**Valeur ajoutÃ©e** : Pipeline 100% temps rÃ©el, format ouvert Parquet, fallback intÃ©grÃ©, monitoring complet, interface utilisateur intuitive.

**Status** : âœ… Production Ready
