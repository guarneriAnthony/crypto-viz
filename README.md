# CryptoViz V3.0 - Data Lakehouse Pipeline ğŸš€

Pipeline temps rÃ©el de donnÃ©es crypto avec architecture data lakehouse moderne, partitioning optimisÃ© et interfaces de monitoring.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Scraper      â”‚â”€â”€â”€â–¶â”‚    Redpanda     â”‚â”€â”€â”€â–¶â”‚  Spark Stream   â”‚â”€â”€â”€â–¶â”‚  MinIO (S3)     â”‚
â”‚   Multi-API     â”‚    â”‚   (Kafka)       â”‚    â”‚   Processing    â”‚    â”‚  Partitioned    â”‚
â”‚ â€¢ CoinMarketCap â”‚    â”‚ â€¢ crypto-raw-dataâ”‚    â”‚ â€¢ Partitioning  â”‚    â”‚ â€¢ Y/M/D struct  â”‚
â”‚ â€¢ CoinGecko     â”‚    â”‚ â€¢ Real-time     â”‚    â”‚ â€¢ Y/M/D columns â”‚    â”‚ â€¢ Parquet       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Dashboard Streamlit                                          â”‚
â”‚          â€¢ Lecture temps rÃ©el MinIO â€¢ Graphiques interactifs â€¢ MÃ©triques live          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ FonctionnalitÃ©s V3.0

### ğŸ”„ Pipeline Temps RÃ©el
- **Scraping multi-sources** : CoinMarketCap + CoinGecko (17 cryptos)
- **Streaming haute performance** : Apache Spark + Redpanda (Kafka)
- **Partitioning intelligent** : Structure annÃ©e/mois/jour optimisÃ©e pour analytics
- **Stockage S3** : MinIO avec compression Snappy

### ğŸ“Š Data Lakehouse
- **Structure partitionnÃ©e** : `year=2025/month=09/day=05/`
- **Format optimisÃ©** : Apache Parquet pour requÃªtes rapides
- **Compression** : Snappy pour rÃ©duction espace disque
- **MÃ©tadonnÃ©es** : Schema evolution et historique complet

### ğŸ¯ Monitoring & UI
- **Redpanda Console** : Monitoring Kafka topics temps rÃ©el
- **MinIO Browser** : Gestion buckets S3 et exploration donnÃ©es
- **Dashboard Streamlit** : Visualisations crypto interactives
- **MÃ©triques** : CPU, mÃ©moire, throughput pipeline

## ğŸš€ DÃ©marrage Rapide

### Prerequisites
```bash
# Docker & Docker Compose requis
docker --version && docker-compose --version
```

### 1. Clonage et Configuration
```bash
git clone <repo-url>
cd crypto-viz
cp .env.example .env
# Ã‰diter .env avec vos API keys
```

### 2. Lancement Pipeline Complet
```bash
# DÃ©marrage complet (tous services)
docker-compose -f docker-compose-v3-final.yml up -d

# VÃ©rification Ã©tat services
docker ps --filter network=crypto-viz_crypto-net
```

### 3. Interfaces Disponibles
- **Dashboard** : http://localhost:8501
- **Redpanda Console** : http://localhost:8090
- **MinIO Browser** : http://localhost:9001 (cryptoviz/cryptoviz2024)

## ğŸ“ Structure DonnÃ©es

### Buckets MinIO
```
crypto-data-partitioned/          # ğŸ¯ DonnÃ©es actuelles (Y/M/D)
â”œâ”€â”€ year=2025/
â”‚   â”œâ”€â”€ month=09/
â”‚   â”‚   â”œâ”€â”€ day=05/
â”‚   â”‚   â”‚   â”œâ”€â”€ part-00000-xxx.snappy.parquet
â”‚   â”‚   â”‚   â””â”€â”€ part-00001-xxx.snappy.parquet
â”‚   â”‚   â””â”€â”€ day=06/...
â”‚   â””â”€â”€ month=10/...
â””â”€â”€ year=2024/...

crypto-data/                      # ğŸ“š Archive historique
â”œâ”€â”€ part-00000-legacy.parquet     # Format non-partitionnÃ© (historique)
â””â”€â”€ ...
```

### Schema DonnÃ©es
```json
{
  "name": "Bitcoin",
  "symbol": "BTC", 
  "price": 67891.23,
  "market_cap": 1337000000000.0,
  "volume_24h": 28500000000.0,
  "change_1h": 0.15,
  "change_24h": 2.34,
  "change_7d": -1.23,
  "source": "coinmarketcap",
  "timestamp": "2025-09-05 20:12:00",
  "ingestion_timestamp": "2025-09-05T20:12:00.123456",
  "year": 2025,
  "month": 9,
  "day": 5
}
```

## âš™ï¸ Configuration Services

### Variables d'Environnement
```bash
# APIs
COINMARKETCAP_API_KEY=your-api-key

# MinIO S3
MINIO_ACCESS_KEY=cryptoviz
MINIO_SECRET_KEY=cryptoviz2024
MINIO_ENDPOINT=http://minio:9000

# Kafka/Redpanda
REDPANDA_BROKERS=redpanda:9092
```

### Tuning Performance
```bash
# Spark Streaming
SPARK_EXECUTOR_MEMORY=1g
SPARK_DRIVER_MEMORY=512m
BATCH_INTERVAL=60s              # Traitement par batch de 60s

# Scraper
SCRAPE_INTERVAL=60s             # Collecte toutes les 60s
MAX_CRYPTOS=17                  # Top 17 cryptos
```

## ğŸ”§ Commandes Maintenance

### Monitoring
```bash
# Ã‰tat pipeline complet
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# Logs services
docker logs crypto_spark_streaming --tail 20
docker logs crypto_scraper --tail 20
docker logs crypto_redpanda --tail 20

# VÃ©rification donnÃ©es MinIO
docker exec crypto_minio mc ls --recursive local/crypto-data-partitioned/
```

### Debug & Troubleshooting
```bash
# Test connectivitÃ© Kafka
docker exec crypto_redpanda rpk topic list
docker exec crypto_redpanda rpk topic consume crypto-raw-data --num 5

# Test MinIO
docker exec crypto_minio mc ls local/

# Restart services
docker-compose -f docker-compose-v3-final.yml restart spark-streaming
```

## ğŸ“ˆ MÃ©triques & Performance

### Throughput Typique
- **Ingestion** : ~17 records/minute (1 crypto/3.5s)
- **Latence E2E** : < 2 minutes (scrape â†’ dashboard)
- **Stockage** : ~5KB/record (compression Snappy)
- **Partitions** : Auto-crÃ©ation quotidienne

### Optimisations V3.0
- âœ… Partitioning Y/M/D pour requÃªtes analytiques rapides
- âœ… Compression Parquet/Snappy (-70% espace disque)
- âœ… Streaming micro-batch (60s) vs polling
- âœ… Cache Streamlit intelligent
- âœ… JAR Kafka auto-tÃ©lÃ©chargement Spark

## ğŸ”„ Ã‰volutions Futures

### Roadmap V3.1
- [ ] Migration Dashboard Streamlit â†’ Panel/Bokeh (WebSocket)
- [ ] IntÃ©gration Spark SQL pour analytics avancÃ©es
- [ ] ML Pipeline (prÃ©dictions prix)
- [ ] Alertes temps rÃ©el (seuils prix)
- [ ] API REST exposition donnÃ©es

### AmÃ©liorations Architecture
- [ ] Auto-scaling Spark Workers
- [ ] Backup automatique MinIO â†’ Cloud S3
- [ ] Monitoring Prometheus/Grafana
- [ ] CI/CD Pipeline automatisÃ©

## ğŸ› ProblÃ¨mes Connus

### Limitations
- **Rate Limiting** : APIs publiques limitÃ©es (60 req/min)
- **DonnÃ©es historiques** : LimitÃ©es aux derniers collectÃ©s
- **Single Point** : Une instance par service (pas HA)

### Solutions
- Utiliser des API keys premium pour rate limits plus Ã©levÃ©s
- ImplÃ©menter backup/restore pour donnÃ©es historiques
- Configurer rÃ©plication services critiques

## ğŸ¤ Contribution

### Development Setup
```bash
# Clone repo
git clone <repo-url>
cd crypto-viz

# Tests unitaires
python -m pytest tests/

# Linting
flake8 src/
black src/
```

### Architecture Decisions
- **Parquet** : Format colonnaire optimisÃ© analytics
- **Partitioning Y/M/D** : Compatible Spark, Hive, Trino
- **Redpanda** : Plus performant que Kafka vanilla
- **MinIO** : Compatible S3, dÃ©ploiement local simple

## ğŸ“„ Licence

MIT License - Voir [LICENSE](LICENSE) pour dÃ©tails.

---

## ğŸ”— Links Utiles

- [Apache Spark Streaming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [MinIO Documentation](https://docs.min.io/)
- [Redpanda Kafka API](https://docs.redpanda.com/)
- [CoinMarketCap API](https://coinmarketcap.com/api/)

**CryptoViz V3.0** - Pipeline Data Lakehouse moderne pour analytics crypto temps rÃ©el ğŸš€
