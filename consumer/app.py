import redis
import json
import duckdb
import time
from datetime import datetime, timedelta
import os
import threading

# Configuration Redis
redis_client = redis.Redis(host="redis", port=6379, db=0)
QUEUE_NAME = "crypto_data"

def check_table_structure():
    """V√©rifie et affiche la structure de la table"""
    try:
        conn = duckdb.connect('/data/crypto_analytics.duckdb', read_only=True)
        
        # V√©rifier si la table existe
        tables = conn.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='crypto_prices'").fetchall()
        
        if not tables:
            print("‚ö†Ô∏è Table crypto_prices n'existe pas encore", flush=True)
            conn.close()
            return None
            
        # Obtenir la structure
        structure = conn.execute("DESCRIBE crypto_prices").fetchall()
        print("üìä Structure actuelle de la table:", flush=True)
        for i, (name, type_info, null_info, key, default, extra) in enumerate(structure):
            print(f"   {i+1}. {name} ({type_info})", flush=True)
        
        conn.close()
        return [col[0] for col in structure]  # Retourner les noms des colonnes
        
    except Exception as e:
        print(f"‚ùå Erreur inspection table: {e}", flush=True)
        return None

def init_database():
    """Initialise la base de donn√©es - compatible avec table existante"""
    try:
        conn = duckdb.connect(database='/data/crypto_analytics.duckdb', read_only=False)
        
        # V√©rifier la structure existante
        existing_columns = check_table_structure()
        
        if existing_columns is None:
            # Table n'existe pas - cr√©er la version standard
            print("üÜï Cr√©ation nouvelle table crypto_prices", flush=True)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS crypto_prices (
                    name VARCHAR,
                    symbol VARCHAR,
                    price DOUBLE,
                    percent_change_24h DOUBLE,
                    market_cap DOUBLE,
                    timestamp TIMESTAMP
                )
            """)
        else:
            print(f"‚úÖ Table existante trouv√©e avec {len(existing_columns)} colonnes", flush=True)
        
        conn.close()
        print("‚úÖ Base de donn√©es initialis√©e", flush=True)
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur d'initialisation DB: {e}", flush=True)
        return False

def get_insert_query():
    """G√©n√®re la requ√™te d'insertion adapt√©e √† la structure de table"""
    try:
        conn = duckdb.connect('/data/crypto_analytics.duckdb', read_only=True)
        structure = conn.execute("DESCRIBE crypto_prices").fetchall()
        conn.close()
        
        columns = [col[0] for col in structure]
        print(f"üìù Colonnes d√©tect√©es: {columns}", flush=True)
        
        # V√©rifier si on a un ID auto-incr√©ment√©
        if 'id' in [col.lower() for col in columns]:
            # Table avec ID - exclure l'ID de l'insertion
            non_id_columns = [col for col in columns if col.lower() != 'id']
            placeholders = ', '.join(['?' for _ in non_id_columns])
            column_names = ', '.join(non_id_columns)
            query = f"INSERT INTO crypto_prices ({column_names}) VALUES ({placeholders})"
            print(f"üîß Mode ID auto: INSERT INTO crypto_prices ({column_names}) VALUES ({placeholders})", flush=True)
        else:
            # Table standard - ins√©rer toutes les colonnes
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT INTO crypto_prices VALUES ({placeholders})"
            print(f"üîß Mode standard: INSERT INTO crypto_prices VALUES ({placeholders})", flush=True)
            
        return query, columns
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration requ√™te: {e}", flush=True)
        # Fallback sur requ√™te standard
        return "INSERT INTO crypto_prices VALUES (?, ?, ?, ?, ?, ?)", ['name', 'symbol', 'price', 'percent_change_24h', 'market_cap', 'timestamp']

def cleanup_old_data_simple():
    """Nettoyage simple - garde 7 jours"""
    try:
        print("üßπ Nettoyage automatique des donn√©es...", flush=True)
        conn = duckdb.connect('/data/crypto_analytics.duckdb', read_only=False)
        
        cutoff_date = datetime.now() - timedelta(days=7)
        before_count = conn.execute("SELECT COUNT(*) FROM crypto_prices").fetchone()[0]
        
        conn.execute("DELETE FROM crypto_prices WHERE timestamp < ?", [cutoff_date])
        conn.execute("VACUUM")
        
        after_count = conn.execute("SELECT COUNT(*) FROM crypto_prices").fetchone()[0]
        conn.close()
        
        print(f"‚úÖ Nettoyage: {before_count - after_count:,} enregistrements supprim√©s", flush=True)
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur nettoyage: {e}", flush=True)
        return False

def start_cleanup_scheduler():
    """Lance le nettoyage automatique"""
    def cleanup_worker():
        last_cleanup = time.time()
        while True:
            if time.time() - last_cleanup > 6 * 3600:  # 6 heures
                cleanup_old_data_simple()
                last_cleanup = time.time()
            time.sleep(3600)
    
    cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
    cleanup_thread.start()
    print("üìÖ Nettoyage automatique activ√© (toutes les 6h)", flush=True)

def process_batch(data_batch):
    """Traite un lot de donn√©es - adapt√© √† la structure avec colonne source"""
    if not data_batch:
        return False
    
    retry_count = 3
    for attempt in range(retry_count):
        try:
            conn = duckdb.connect(database='/data/crypto_analytics.duckdb', read_only=False)
            conn.begin()
            
            # Pr√©parer les donn√©es avec la colonne source
            insert_data = []
            for crypto_item in data_batch:
                # Ordre exact des colonnes : name, symbol, price, percent_change_24h, market_cap, source, timestamp
                values = (
                    crypto_item['name'],
                    crypto_item['symbol'],
                    crypto_item['price'],
                    crypto_item['percent_change_24h'],
                    crypto_item['market_cap'],
                    'coinmarketcap',  # NOUVELLE colonne source
                    crypto_item['timestamp']
                )
                insert_data.append(values)
            
            # Insertion avec toutes les 7 colonnes
            conn.executemany("""
                INSERT INTO crypto_prices (name, symbol, price, percent_change_24h, market_cap, source, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, insert_data)
            
            conn.commit()
            conn.close()
            
            print(f"‚úÖ Batch de {len(data_batch)} enregistrements trait√©s (source: coinmarketcap)", flush=True)
            return True
            
        except Exception as e:
            print(f"‚ùå Tentative {attempt + 1}/{retry_count} - Erreur: {e}", flush=True)
            try:
                conn.rollback()
                conn.close()
            except:
                pass
                
            if attempt < retry_count - 1:
                time.sleep(1 + attempt)
            else:
                print(f"üî• √âchec d√©finitif du batch", flush=True)
                print(f"üîç Debug - Query: {insert_query}", flush=True)
                print(f"üîç Debug - Colonnes: {columns}", flush=True)
                print(f"üîç Debug - Exemple data: {data_batch[0] if data_batch else 'None'}", flush=True)
                return False

def process_data():
    """Fonction principale"""
    print("üöÄ Consumer avec d√©tection automatique de structure d√©marr√©...", flush=True)
    
    # Initialiser la base
    for attempt in range(3):
        if init_database():
            break
        print(f"Tentative d'initialisation {attempt + 1}/3 √©chou√©e, retry dans 3s...", flush=True)
        time.sleep(3)
    else:
        print("üî• Impossible d'initialiser la base de donn√©es", flush=True)
        return
    
    # D√©marrer le nettoyage automatique
    start_cleanup_scheduler()
    
    batch = []
    batch_size = 10
    last_batch_time = time.time()
    
    print("üì• En attente des donn√©es Redis...", flush=True)
    
    while True:
        try:
            data = redis_client.brpop(QUEUE_NAME, timeout=5)
            
            if data:
                crypto_item = json.loads(data[1])
                batch.append(crypto_item)
                print(f"üì• Batch +1: {crypto_item['name']} ({len(batch)}/{batch_size})", flush=True)
                
                if len(batch) >= batch_size or (time.time() - last_batch_time) > 30:
                    print(f"üîÑ Traitement batch de {len(batch)} √©l√©ments...", flush=True)
                    if process_batch(batch):
                        batch = []
                        last_batch_time = time.time()
                    else:
                        batch = batch[-batch_size//2:] if len(batch) > batch_size//2 else batch
                        print(f"‚ö†Ô∏è √âchec batch, conservation de {len(batch)} √©l√©ments", flush=True)
                        
            else:
                if batch:
                    print(f"‚è∞ Timeout Redis, traitement batch partiel ({len(batch)} items)", flush=True)
                    if process_batch(batch):
                        batch = []
                        last_batch_time = time.time()
                else:
                    print("üí§ Aucune nouvelle donn√©e...", flush=True)
                
        except redis.exceptions.ConnectionError as e:
            print(f"üîå Erreur connexion Redis: {e}, retry dans 10s...", flush=True)
            time.sleep(10)
        except Exception as e:
            print(f"üí• Erreur dans la boucle principale: {e}", flush=True)
            time.sleep(5)

if __name__ == "__main__":
    process_data()